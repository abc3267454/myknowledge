++ 实验



数据集的大小
Noise比率
约束的数目
再加一个准确率的度量，如果真实数据集上这个比较麻烦的话，至少在人工数据集上面是可以作的。就参考那两篇文章，用正确改正的数目/本来的修改数目，或者之类的度量方法。这里需要注意就是weight生成的时候，要象第二篇文章那样假定在人工数据集上引入noise的部分weight会比较大，这样有利于做出正确的修改。

另外就是要给出文档内节点的总数目，value node，target node的数目，再加上你已经给出的超边的数目。这样可以看一下超边和value node等等的大致关系。还有就是那个文档上value node总的weight大小，和最终修复的weight大小；这个显然也和noise比率相关的。理想情况下，最终修复的weight大小应该比总的weight大小增长的慢；超边的数目也比理论分析增长的慢。不过要做出来才知道了:) 不一定最后都会做图，但是最好可以看一下结果情况。
从目前的结果来看，主要的时间几乎都消耗在两次找超边上，似乎至少第二次是可以有所优化的。